---
title: What Annie Duke and Nate Silver forget about betting
weight: 2
---
A good bet is quantifiable. With poker you mix three different, measurable things together, 1) the chance my hand will improve based on the next card 2) The chance an opponent has a better hand 3) the amount of money I have to pay into the pot to see that bet through.

I'm no expert on poker but here's a quick scenario. Say there's a 25% chance by hand will be a really good on the next card. And someone has bet money but it's only 20% of the pot (all the money lying on the table,) then it's a good bet. There's a 5% difference, which means if I take this bet every time, about 1 in every 4 times, I'll make 5%. Now obviously it's way way way more complex than that, but that is poker odds in a nutshell.

But poker is really really different than real life. Annie Duke says real life isn't like chess, it's like poker. Chess is an extremely large decision tree with explicit answers at the end. Poker is a game of imperfect information where you can never know all of the moving parts. In a way that makes poker simpler than chess, because what you don't know is so large that you actually can't act on it, and what you need to do to act on the limited information is much simpler. The real art of poker isn't in winning individual hands or even dominating games. It's in finding a nice place to play where you're always up against players who make bad bets.

Chess is not a game of perfect information. If you turn every card in a poker deck you will now know everything and it gets significantly easier to play the game. Chess is already like that. Metaphorically every card is turned face up and yet people still can't win. The decision space in chess is so large that humans lose to computers, which, one could argue, means that lack of ability to fully know something even if all the information is there is another form of fog of war.

Real life is like real life. The issue with real life is that it's not a synecdoche, a simulacrum, a metaphor. It just is what it is. It is both vastly incalculable, and fully of hidden information.

Ask a customer what they want and they will tell you. Build the product, and they may not care at all. I've decided I need things before, only to test them out and learn I'm fine using the old thing.

Jobs argues you need a complete sea change which is what the iPhone was, but apparently his management style was to walk into a room and berate people until they built a thing he couldn't build or properly describe on his own. A sea change is easy to spot in retrospect but many people are creating products that are paradigm shifts that absolutely no one cares about. This is survivorship bias in a nutshell. If the iPhone is the sea change of telecom, shouldn't the Neuralink or the Google glass be the next step? However no one wants it and no one can build it. Maybe time will prove me wrong, but these companies have an unreasonable amount of certainty around things.

Unquantifiable actually. They have an unquantifiable amount of certainty. That's the crux of my gripe with Nate Silver and Annie Duke. It's not that they aren't geniuses, they are. They are incredibly accomplished, talented, and intelligent.

The issue is if you want to make a bet, how do you put percentages on outcomes. Nate Silver says this is all in model making. Find a good model, get good insight, combine the models and insight. Annie Duke plays with a poker deck which has very fixed odds. But to make a model, you often need a ton of industry insight and a huge amount of skill in math or computers in order to build it and run it. And as Nate Silver states, your model has to be constantly competing and improving with other models or you are losing your edge against them. They have a more accurate picture and can make better bets, so your bets are always going to be less optimal than theirs and since you are playing a betting game against them, you will lose more often.

So the real issue is, you live in a world with no numbers attached to things, and you need to make a bet, you need to go out there and put money, time, effort, reputation on the line, and if you want to be betting accurately, you need a model to bet with. And you don't have a model, so you have to create one or buy one. And often your skill isn't in model making, it's in something completely different, and you have no money to buy into an expensive model. So it's all good and well to say we should go out there and quantify, learn, rinse and repeat, but practically how does anyone do that if they aren't already obsessed with model making, statistics, computers, or have a ton of money to throw at analysts.

The other issue is auditing models. You have to audit them constantly and they are competitive. Not only is it an issue that your own internal models or auditors could be lying to you, but there can be some underlying complexity throwing everyone in the industry off, or some adversarial mechanics your opponents are using that mess you up. So, very often, if you can build a giant predictive model, you may not always be able to trust it.

As much as I like to complain though, Annie Duke has two great pieces of advice. One, create a community of betterment. Find people who will help you analyze your methods and come up with insights you couldn't see. I guarantee you have blind spots. Two, make bets on things. In your head, you don't need to do it for money. But what is the chance the bus you're waiting for comes in on time. What is the chance your boss will walk around the corner right now. You may not be entirely accurate, but you will start thinking about the things that cause the bus to be late, early, etc, and whether or not these are things you can predict. You might even start thinking about ways to get information that would predict this in the future.

Good luck!